{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+yTF5rkjN+mDBzm0M9A1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikramebakkari/C-Programming-Project/blob/main/CudaTD1%262.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWxhfTqmae-z",
        "outputId": "75577529-b024-49fe-95ed-eb41897d75cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-0x4ghx1c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-0x4ghx1c\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=8def43b495941275d2626e2a8be97ba93ca3726d7bd1d1daa324bee35f0ea536\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5j6fmr3w/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc  --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNZwInRSLegt",
        "outputId": "30a2b542-6946-4ac4-9104-17e0e7912b85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP6ipaLdNvCq",
        "outputId": "d858b163-b1bb-456a-ea27-5b079dd03d33"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "    // Execice 1 : Addition de deux entiers\n",
        "__global__ void add (int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "    int a, b, c;\n",
        "    // host copies of variables a, b & c\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    int size = sizeof(int);\n",
        "    // Allocate space for device copies of a, b, c\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "    // Setup input values\n",
        "    c = 0;\n",
        "    a = 3;\n",
        "    b = 5;\n",
        "\n",
        "    // Copy inputs to device\n",
        "    cudaMemcpy (d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy (d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch add() kernel on GPU\n",
        "    add<<<1,1>>>(d_a, d_b, d_c);\n",
        "    // Copy result back to host\n",
        "    cudaError err = cudaMemcpy (&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    if(err!=cudaSuccess) {\n",
        "        printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "\n",
        "    printf(\"first value is %d\\n\", a);\n",
        "    printf(\"secon value is %d\\n\", b);\n",
        "    printf(\"result is %d\\n\", c);\n",
        "    printf(\"error here %s\\n\", cudaGetErrorString(err));\n",
        "    // Cleanup\n",
        "    cudaFree (d_a); cudaFree (d_b); cudaFree (d_c) ;\n",
        "    return a+b;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHqhCXoCOXeE",
        "outputId": "e63cab0d-7d13-4422-f378-e1e7aa20380a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first value is 3\n",
            "secon value is 5\n",
            "result is 8\n",
            "error here no error\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define N 10 // Ou toute autre valeur que vous souhaitez pour la taille des vecteurs\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < N) {\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N], b[N], c[N];\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    // Allocation de mémoire pour les vecteurs sur le GPU\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Initialisation des vecteurs a et b sur le CPU\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        a[i] = i;\n",
        "        b[i] = i * 2;\n",
        "    }\n",
        "\n",
        "    // Copie des vecteurs a et b du CPU au GPU\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numBlocks = 1;\n",
        "    int threadsPerBlock = N;\n",
        "    add<<<numBlocks, threadsPerBlock>>>(d_a, d_b, d_c);\n",
        "\n",
        "    // Copie du résultat du GPU au CPU\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Affichage du résultat\n",
        "    printf(\"Vecteur résultant de l'addition : \\n\");\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    // Libération de la mémoire allouée sur le GPU\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N56KvK48e2_O",
        "outputId": "a856a30b-94fe-47f8-de1f-f6e8e005d022"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vecteur résultant de l'addition : \n",
            "0 + 0 = 0\n",
            "1 + 2 = 3\n",
            "2 + 4 = 6\n",
            "3 + 6 = 9\n",
            "4 + 8 = 12\n",
            "5 + 10 = 15\n",
            "6 + 12 = 18\n",
            "7 + 14 = 21\n",
            "8 + 16 = 24\n",
            "9 + 18 = 27\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define N 4 // Taille des matrices (N x N)\n",
        "\n",
        "__global__ void matrixMultiply(int *a, int *b, int *c, int n) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    int sum = 0;\n",
        "    for (int k = 0; k < n; k++) {\n",
        "        sum += a[row * n + k] * b[k * n + col];\n",
        "    }\n",
        "\n",
        "    c[row * n + col] = sum;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int a[N][N], b[N][N], c[N][N];\n",
        "    int *dev_a, *dev_b, *dev_c;\n",
        "\n",
        "    // Allocation de mémoire sur le GPU\n",
        "    cudaMalloc((void **)&dev_a, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&dev_b, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&dev_c, N * N * sizeof(int));\n",
        "\n",
        "    // Initialisation des matrices a et b sur le CPU\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            a[i][j] = i * N + j;\n",
        "            b[i][j] = j * N + i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copie des matrices du CPU vers le GPU\n",
        "    cudaMemcpy(dev_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Définir la taille des blocs et des grilles\n",
        "    dim3 threadsPerBlock(N, N);\n",
        "    dim3 numBlocks(1, 1);\n",
        "\n",
        "    // Appel du kernel pour la multiplication des matrices\n",
        "    matrixMultiply<<<numBlocks, threadsPerBlock>>>(dev_a, dev_b, dev_c, N);\n",
        "\n",
        "    // Copie du résultat du GPU vers le CPU\n",
        "    cudaMemcpy(c, dev_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Affichage du résultat\n",
        "    printf(\"Résultat de la multiplication :\\n\");\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            printf(\"%d \", c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Libération de la mémoire allouée sur le GPU\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdLsz8EUgY-0",
        "outputId": "6a98f526-373e-47ef-f8fb-8151efe5236e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultat de la multiplication :\n",
            "14 38 62 86 \n",
            "38 126 214 302 \n",
            "62 214 366 518 \n",
            "86 302 518 734 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define N 5 // Taille des matrices (N x N)\n",
        "#define blockSize 2 // Taille du bloc de threads\n",
        "\n",
        "__global__ void matrixMultiply(int *a, int *b, int *c, int n) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    int sum = 0;\n",
        "    for (int k = 0; k < n; k++) {\n",
        "        int a_element = a[row * n + k];\n",
        "        int b_element = b[k * n + col];\n",
        "        sum += a_element * b_element;\n",
        "    }\n",
        "\n",
        "    if (row < n && col < n) {\n",
        "        c[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int a[N][N], b[N][N], c[N][N];\n",
        "    int *dev_a, *dev_b, *dev_c;\n",
        "\n",
        "    // Allocation de mémoire sur le GPU\n",
        "    cudaMalloc((void **)&dev_a, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&dev_b, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&dev_c, N * N * sizeof(int));\n",
        "\n",
        "    // Initialisation des matrices a et b sur le CPU\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            a[i][j] = i * N + j;\n",
        "            b[i][j] = j * N + i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copie des matrices du CPU vers le GPU\n",
        "    cudaMemcpy(dev_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Définir la taille des blocs et des grilles\n",
        "    dim3 threadsPerBlock(blockSize, blockSize);\n",
        "    dim3 numBlocks((N + blockSize - 1) / blockSize, (N + blockSize - 1) / blockSize);\n",
        "\n",
        "    // Appel du kernel pour la multiplication des matrices\n",
        "    matrixMultiply<<<numBlocks, threadsPerBlock>>>(dev_a, dev_b, dev_c, N);\n",
        "\n",
        "    // Copie du résultat du GPU vers le CPU\n",
        "    cudaMemcpy(c, dev_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Affichage du résultat\n",
        "    printf(\"Résultat de la multiplication :\\n\");\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            printf(\"%d \", c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Libération de la mémoire allouée sur le GPU\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPUntJNcg4X7",
        "outputId": "9f2c8361-6dfb-4165-f12a-17fad5d7cf4f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultat de la multiplication :\n",
            "30 80 130 180 230 \n",
            "80 255 430 605 780 \n",
            "130 430 730 1030 1330 \n",
            "180 605 1030 1455 1880 \n",
            "230 780 1330 1880 2430 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 10 // Taille d'une dimension de la matrice\n",
        "\n",
        "// Kernel pour la multiplication de matrices\n",
        "__global__ void matrixMultiply(int *a, int *b, int *c) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    int sum = 0;\n",
        "    for (int k = 0; k < N; k++) {\n",
        "        sum += a[row * N + k] * b[k * N + col];\n",
        "    }\n",
        "\n",
        "    c[row * N + col] = sum;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int a[N][N], b[N][N], c[N][N];\n",
        "    int *gpu_a, *gpu_b, *gpu_c;\n",
        "    int size = N * N * sizeof(int);\n",
        "\n",
        "    // Allocation de l espace pour les copies sur le GPU de a, b et c\n",
        "    cudaMalloc((void **)&gpu_a, size);\n",
        "    cudaMalloc((void **)&gpu_b, size);\n",
        "    cudaMalloc((void **)&gpu_c, size);\n",
        "\n",
        "    // Initialisation des valeurs dans les matrices a et b\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            a[i][j] = j * i + i;\n",
        "            b[i][j] = j * i + i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copie des matrices d'entrée vers le GPU\n",
        "    cudaMemcpy(gpu_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 blockDim(2, 2); // Taille du bloc de threads\n",
        "    dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y); // Taille de la grille\n",
        "\n",
        "    // Appel du kernel\n",
        "    matrixMultiply<<<gridDim, blockDim>>>(gpu_a, gpu_b, gpu_c);\n",
        "\n",
        "    // Copie du résultat de retour vers le CPU\n",
        "    cudaMemcpy(c, gpu_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Affichage du résultat\n",
        "    printf(\"Résultat de la multiplication :\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Libération de la mémoire allouée sur le GPU\n",
        "    cudaFree(gpu_a);\n",
        "    cudaFree(gpu_b);\n",
        "    cudaFree(gpu_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV2wgNKThQgk",
        "outputId": "92ba8d59-93c0-42e4-9581-5e493881ae15"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultat de la multiplication :\n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "330 660 990 1320 1650 1980 2310 2640 2970 3300 \n",
            "660 1320 1980 2640 3300 3960 4620 5280 5940 6600 \n",
            "990 1980 2970 3960 4950 5940 6930 7920 8910 9900 \n",
            "1320 2640 3960 5280 6600 7920 9240 10560 11880 13200 \n",
            "1650 3300 4950 6600 8250 9900 11550 13200 14850 16500 \n",
            "1980 3960 5940 7920 9900 11880 13860 15840 17820 19800 \n",
            "2310 4620 6930 9240 11550 13860 16170 18480 20790 23100 \n",
            "2640 5280 7920 10560 13200 15840 18480 21120 23760 26400 \n",
            "2970 5940 8910 11880 14850 17820 20790 23760 26730 29700 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 10 // Taille d'une dimension de la matrice\n",
        "#define TILE_SIZE 2 // Taille de la tuile\n",
        "\n",
        "// Kernel pour la multiplication de matrices avec la méthode de tuile\n",
        "__global__ void matrixMultiplyTiled(int *a, int *b, int *c) {\n",
        "    __shared__ int tile_a[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ int tile_b[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    int row = blockIdx.y * TILE_SIZE + threadIdx.y;\n",
        "    int col = blockIdx.x * TILE_SIZE + threadIdx.x;\n",
        "\n",
        "    int sum = 0;\n",
        "    for (int t = 0; t < N / TILE_SIZE; t++) {\n",
        "        tile_a[threadIdx.y][threadIdx.x] = a[row * N + t * TILE_SIZE + threadIdx.x];\n",
        "        tile_b[threadIdx.y][threadIdx.x] = b[(t * TILE_SIZE + threadIdx.y) * N + col];\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_SIZE; k++) {\n",
        "            sum += tile_a[threadIdx.y][k] * tile_b[k][threadIdx.x];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    c[row * N + col] = sum;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int a[N][N], b[N][N], c[N][N];\n",
        "    int *gpu_a, *gpu_b, *gpu_c;\n",
        "    int size = N * N * sizeof(int);\n",
        "\n",
        "    // Allocation de l'espace pour les copies sur le GPU de a, b et c\n",
        "    cudaMalloc((void **)&gpu_a, size);\n",
        "    cudaMalloc((void **)&gpu_b, size);\n",
        "    cudaMalloc((void **)&gpu_c, size);\n",
        "    cudaMemcpy(gpu_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 blockDim(TILE_SIZE, TILE_SIZE); // Taille de la tuile\n",
        "    dim3 gridDim(N / TILE_SIZE, N / TILE_SIZE); // Taille de la grille\n",
        "\n",
        "    // Appel du kernel\n",
        "    matrixMultiplyTiled<<<gridDim, blockDim>>>(gpu_a, gpu_b, gpu_c);\n",
        "\n",
        "    // Copie du résultat de retour vers le CPU\n",
        "    cudaMemcpy(c, gpu_c, size, cudaMemcpyDeviceToHost);\n",
        "    // Libération de la mémoire allouée sur le GPU\n",
        "    cudaFree(gpu_a);\n",
        "    cudaFree(gpu_b);\n",
        "    cudaFree(gpu_c);\n",
        "        // Affichage du résultat\n",
        "    printf(\"Résultat de la multiplication en tiles :\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", c[i][j]);\n",
        "        }\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"ici a  %d \", a[i][j]);\n",
        "        }\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"ici b  %d \", b[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ2M431AhVVJ",
        "outputId": "61aff270-a872-4f37-c32d-28b9148df725"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultat de la multiplication en tiles :\n",
            "-1065569792 0 1610297120 1338185920 -1440385248 1338185920 0 0 -1016041280 0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  3167716 ici a  0 ici a  -1016041280 ici a  32767 ici b  -1415766019 ici b  23472 ici b  1630256366 ici b  30749 ici b  -1415110624 ici b  23472 ici b  -1415131104 ici b  23472 ici b  0 ici b  0 \n",
            "-1355373206 -1002870621 -1453010116 747406027 -556822904 602613916 -2068742418 -1460436735 1728850658 -1597799398 ici a  1627922298 ici a  30749 ici a  1630160240 ici a  30749 ici a  -1016041440 ici a  32767 ici a  -1016041424 ici a  32767 ici a  1630216721 ici a  30749 ici b  -1016040136 ici b  32767 ici b  1630409440 ici b  30749 ici b  1630015344 ici b  30749 ici b  1 ici b  0 ici b  1630410752 ici b  30749 \n",
            "-1201366574 -990483680 -1135452132 -712404102 324630585 17068803 257816118 -349868351 1 0 ici a  2 ici a  0 ici a  1630161984 ici a  30749 ici a  1 ici a  0 ici a  0 ici a  0 ici a  1 ici a  0 ici b  1 ici b  32767 ici b  1630359273 ici b  30749 ici b  -1016041216 ici b  32767 ici b  8064 ici b  65535 ici b  0 ici b  0 \n",
            "1558321184 -746096813 147678624 -560115575 -782367928 199380716 -1254149300 1308723343 768748703 1737122424 ici a  1630159360 ici a  30749 ici a  1630161984 ici a  30749 ici a  1630159360 ici a  30749 ici a  0 ici a  1 ici a  1630160240 ici a  30749 ici b  0 ici b  0 ici b  0 ici b  0 ici b  -1015467400 ici b  32767 ici b  0 ici b  32 ici b  0 ici b  0 \n",
            "-3480 0 0 0 -96 0 0 0 -1 0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  -1 ici a  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  1 ici b  0 ici b  61765110 ici b  1 ici b  0 ici b  0 \n",
            "1630169352 -749103368 -637401016 -485906968 426609288 258449115 1682615968 1763353992 0 0 ici a  0 ici a  0 ici a  1630169352 ici a  30749 ici a  1630407408 ici a  30749 ici a  0 ici a  0 ici a  0 ici a  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 \n",
            "0 0 0 0 0 0 0 0 0 0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici a  0 ici b  0 ici b  0 ici b  -1415110648 ici b  23472 ici b  -1415110648 ici b  23472 ici b  0 ici b  0 ici b  0 ici b  0 \n",
            "-418712999 -525271312 -1229043202 -1490780055 -794085672 -766682429 -1313270336 2017951896 -505612944 909518160 ici a  13 ici a  0 ici a  1630159360 ici a  30749 ici a  1630007736 ici a  30749 ici a  -1415766019 ici a  23472 ici a  -1415131104 ici a  23472 ici b  -1415110648 ici b  23472 ici b  0 ici b  0 ici b  0 ici b  0 ici b  791621423 ici b  791621423 ici b  791621423 ici b  791621423 \n",
            "-1742939447 -867048334 -990160199 937128534 190415689 78452667 1330208147 1477140528 -22863608 945501001 ici a  1630404672 ici a  30749 ici a  1630244721 ici a  30749 ici a  1 ici a  0 ici a  0 ici a  0 ici a  1630169352 ici a  30749 ici b  3480 ici b  0 ici b  0 ici b  0 ici b  96 ici b  0 ici b  0 ici b  0 ici b  1 ici b  0 \n",
            "788313176 -1242305565 86665704 -209444167 -1046175384 -1304333575 1266934077 1029068976 1625894200 945501001 ici a  1630279360 ici a  30749 ici a  8388608 ici a  0 ici a  -1016040272 ici a  32767 ici a  1 ici a  0 ici a  -1016040136 ici a  32767 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 ici b  0 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}